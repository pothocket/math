%&pdflatex 
\documentclass[12pt]{article} 
\usepackage[margin=1in]{geometry} 
\usepackage{amsmath,amsthm,amssymb,amsfonts,tikz-cd, mathrsfs} 

\newenvironment{problem}[2][Problem]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}

\newenvironment{proposition}[1][Proposition]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1.}]}{\end{trivlist}}

\newenvironment{definition}[1][Definition]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1.}]}{\end{trivlist}}

\newcommand{\til}{\char`\~}
\newcommand{\bs}{\textbackslash} 

\newcommand{\catname}[1]{\normalfont\textbf{#1}}
\newcommand{\catsup}[2]{\normalfont\textbf{#1}^{#2}}
\newcommand{\catsub}[2]{\normalfont\textbf{#1}_{#2}}

\newcommand{\Hom}{\text{Hom}}
\newcommand{\Homc}[2]{\Hom_{\catname{#1}}(#2)}

\newcommand{\Obj}{\text{Obj}}
\newcommand{\Objc}[1]{\text{Obj}(\catname{#1})}
\newcommand{\Aut}{\text{Aut}}
\newcommand{\End}{\text{End}}

\newcommand{\id}{\text{id}}
\newcommand{\im}{\text{im }}

\newcommand{\lcm}[1]{\text{lcm}(#1)}

\newenvironment{solution}
  {\renewcommand\qedsymbol{$\blacksquare$}\begin{proof}[Solution]}
{\end{proof}}

\newenvironment{sproof}{
  \renewcommand\qedsymbol{$\square$}
  \begin{proof}
  }{
  \end{proof}
}

\newtheorem{lemma}{Lemma}

\theoremstyle{remark}
\newtheorem*{exmp}{Example}
\newtheorem*{cexmp}{Counterexample}


\begin{document}

\title{Algebra: Chapter 0 Exercises\\ \large Chapter 3, Section 3}
\author{David Melendez}
\maketitle

\begin{problem}{3.1}
  Prove that the image of a ring homomorphism $\varphi:R\to S$ is a subring of $S$.
  What can you say about $\varphi$ if its image is an ideal of $S$?
  What can you say about $\varphi$ if its kernel is a subring of $R$?
\end{problem}
\begin{solution}
  First we'll prove that $\im \varphi$ is a subring of $S$.
  \begin{sproof}
    Suppose $s_1=\varphi(r_1)$ and $s_2=\varphi(r_2)$ are elements of $\im\varphi$.
    We then have \\ $s_1+s_2=\varphi(r_1+r_2)$ and $s_1s_2=\varphi(r_1r_2)$ since $\varphi$
    is a homomorphism, so both of these are elements of $\im\varphi$.
    Additionally, $\varphi(1_R)=1_S$, making $\im\varphi$ a subring of $S$.
  \end{sproof}
  If $\im\varphi$ is an ideal of $S$, then $\varphi$ is surjective, since the only ideal of $S$
  containing the identity $1_S$ is $S$ itself.
  If $\ker\varphi$ is a subring of $R$, then it must contain $1_R$, which, combined with
  the fact that $\ker\varphi$ is an ideal, tells us that $\ker\varphi=R$. Thus $\varphi$
  must be the "zero" morphism $r\mapsto 0$, which isn't actually a ring homomorphism since it
  does not preserve the identity.
\end{solution}

\begin{problem}{3.2}
  Let $\varphi:R\to S$ be a ring homomorphism, and let $J$ be an ideal of $S$.
  Prove that $I=\varphi^{-1}(J)$ is an ideal of $R$.
\end{problem}
\begin{solution}
  Suppose $x\in I$ and $r\in R$.
  We then have $\varphi(rx) = \varphi(r)\varphi(x)$, which is in $J$ since $J$ is an ideal and
  $\varphi(x)\in J$.
  The same argument applies to $xr$ (as $J$ is a two-sided ideal), so $I$ is an ideal of $R$.
\end{solution}

\begin{problem}{3.3}
Let $\varphi:R\to S$ be a ring homomorphism, and let $J$ be an ideal of $R$.
\end{problem}
\begin{enumerate}
  \item Show that $\varphi(J)$ need not be an ideal of S.
    \begin{sproof}
      Let $R=\mathbb{C}$ and $S=\mathbb{H}$ (the quaternions), and let $\iota:\mathbb{C}\to\mathbb{H}$ be the
      inclusion \\$a+bi\mapsto a+bi$.
      The whole of $\mathbb{C}$ is of course an ideal of $\mathbb{C}$, but
      the "copy" of $\mathbb{C}$ in the quaternions $\iota(\mathbb{C})$ is not an ideal
      of $\mathbb{H}$, since $(a+bi)j = aj+bk\notin\iota(\mathbb{C})$.
    \end{sproof}
  \item Assume that $\varphi$ is surjective; then prove that $\varphi(J)$ \textit{is} an ideal of $S$.
    \begin{proof}
    We already know that $\varphi(J)$ is a subgroup of $S$ since $J$ is a subgroup of $R$, so
    let $s\in S$ and $i\in \varphi(J)$.
    There then exists a $j\in J$ such that $i=\varphi(j)$, and since $\varphi$ is 
    surjective, there exists an $r\in R$ such that $s=\varphi(r)$.
    Note, then, that  
      \begin{align*}
        si &= \varphi(r)\varphi(j) \\
           &= \varphi(rj)\\
           &\in \varphi(J),
      \end{align*}
      since $rj$ is in $J$ due to the fact that $J$ is an ideal; 
      hence $\varphi(J)$ is a left-ideal in $S$.
      A similar argument shows that $\varphi(J)$ is also a right-ideal in $S$.
    \end{proof}
  \item Assume that $\varphi$ is surjective, and let $I=\ker\varphi$; thus we may identify
  $S$ with $R/I$.
  Let $\overline J=\varphi(J)$, an ideal of $R/I$ by the previous point.
  Prove that
  \begin{equation*}
    \frac{R/I}{\overline{J}}\cong\frac{R}{I+J}.
  \end{equation*}
    \begin{sproof}
      Denote by $\psi$ the surjective ring homomorphism 
      $R\to \displaystyle\frac{S}{\overline{J}}$ defined by the following chain
      of homomorphisms:
      \[
      \begin{tikzcd}
      & R \ar[r, twoheadrightarrow] & \displaystyle{\frac{R}{I}}
          \ar[r, twoheadrightarrow] & \displaystyle{\frac{R/I}{\widetilde{\varphi}^{-1}(\overline{J})}}
          \ar{r}{\widetilde\iota} & \displaystyle{\frac{S}{\overline{J}}}
      \end{tikzcd}
      \]
      where $\widetilde\varphi$ is the isomorphism $r+I\mapsto\varphi(r)$, and
      $\overline\iota$ is the isomorphism \\
      $(r+I)+\widetilde\varphi^{-1}(\overline{J})
      \mapsto \widetilde\varphi(r+I) + \widetilde\varphi(\widetilde\varphi^{-1}(\overline{J}))
      = \varphi(r) + \overline{J}$.
      Hence $\psi$ is defined by \\ $\psi(r) = \varphi(r)+J$.
      Note, then, that $r\in\ker\psi$ if and only if $\varphi(r)\in\varphi(J)$, if and
      only if there exists a $j\in R$ such that $\varphi(r)=\varphi(j)$,
      or equivalently $\varphi(r-j)=0$, which is true if and only if
      there exists some $\nu\in\ker\varphi=I$ such that $r-j=\nu$ (equivalently $r=\nu+j$),
      if and only if $r\in I+J$.\\
        \indent Thus, by the first isomorphism theorem for rings, we have:
        \begin{equation*}
          \frac{R}{I+J} \cong \frac{S}{\overline{J}} 
          \cong \frac{R/I}{\widetilde\varphi^{-1}(\overline{J})}.
        \end{equation*}
        If we identify $\widetilde\varphi^{-1}(\overline{J})$ with $\overline{J}$ in the
        last quotient ring (such an identification can be done in good conscience
        since doing so using any isomorphism between $R/I$ and $S$ yields isomorphic 
        quotient rings), we can then say that
          \begin{equation*}
            \frac{R}{I+J} \cong \frac{R/I}{\overline{J}} .
          \end{equation*}
    \end{sproof}
\end{enumerate}

\newpage

\begin{problem}{3.4}
  Let $R$ be a ring such that every subgroup of $(R,+)$ is in fact an ideal of $R$.
  Prove that $R\cong\mathbb{Z}/n\mathbb{Z}$, where $n$ is the characteristic of $R$.
\end{problem}
\begin{solution}
  Since every subgroup of $R$ is an ideal of $R$, note that in particular, the subgroup
  $I=\langle1_R\rangle$ generated by the identity element is an ideal of $R$.
  Note, then, that for all $r\in R$, we have $r1_R=r\in I$, since
  $1_R\in I$, and so $R$ is actually cyclic, with order equal to the order of $1_R$; in other
  words, the characteristic $n$ of $R$.
  The unique map $\varepsilon:\mathbb{Z}\to R$ is then surjective (since $R$ is generated
  by $1_R$ as a group) and has kernel $n\mathbb{Z}$; hence, by the first isomorphism theorem
  for rings, we have $R\cong\mathbb{Z}/n\mathbb{Z}$.
\end{solution}

\begin{problem}{3.5}
  Let $J$ be a two-sided ideal of the ring $\mathcal{M}_n(R)$ of $n\times n$ matrices over a ring $R$.
  Prove that a matrix $A\in \mathcal{M}_n(R)$ belongs to $J$ if and only if the matrices obtained by 
  placing any entry of $A$ in any position, and 0 elsewhere, belong to $J$.
\end{problem}
\begin{solution}
  First suppose that $A\in J$. 
  For natural numbers $i,j,a,b$ less than $n$, We will "find" the matrix $B$ in $J$
  with $A_{ij}$ at position $a,b$. \\
  \indent Let $\eta(p,q)$ the matrix with $1$ in the entry at position $(q,p)$ and $0$ 
  elsewhere, and let $B=\eta(a,i)A\eta(j,b)$.
  Let $\delta$ be the kronecker delte, and note, then, that
    \begin{align*}
      B_{xy} &= \sum_{k=1}^{n} \eta(a,i)_{xk}(A\eta(j,b))_{ky}\\
      &= \delta_{xa} (A\eta(j,b))_{iy} \\
      &= \delta_{xa} \sum_{k=1}^n A_{ik}\eta(j,b)_{ky}\\ 
      &= \delta_{xa} \delta_{yb} A_{ij};
    \end{align*}
  hence $B$ is the matrix with $A_{ij}$ at position $(a,b)$ and $0$ elsewhere. 
  Since $B$ was obtained by multiplying $A$ on the left and the right by other matrices, 
  it is an element of $J$, as $J$ is a two-sided ideal.
  This completes the proof in one direction. \\
  \indent For the proof in the other direction, suppose the matrices obtained by placing any
  entry of $A$ in ny position, and 0 elsewhere, belong to $J$.
  Then, of course, $A$ is the sum of the matrices that have $A_{ij}$ at position $(i,j)$ where
  $i,j$ range from $1$ to $n-1$; since $J$ is a subgroup of $R$, this matrix is in $J$.
\end{solution}

\begin{problem}{3.6}
  Let $J$ be a two-sided ideal of the ring $\mathcal{M}_n(R)$ of $n\times n$ matrices over a ring $R$,
  and let $I\subseteq R$ be the set of $(1,1)$ entries in $J$.
  Prove that $I$ is a two-sided ideal of $R$ and $J$ consists precisely of those matrices whose
  entries all belong to $I$.
\end{problem}
\begin{solution}
  First we will prove that $I$ is a two-sided ideal of $R$.
  Suppose $r\in I$, and $a\in R$.
  By exercise 3.5, then, the matrix $r\cdot\eta(1,1)$ is in $J$, and so 
  $(r\cdot\eta(1,1))(a\cdot\eta(1,1))=(ra\cdot\eta(1,1))\in J$ since $J$ is a right-ideal of
  $\mathcal{M}_n(R)$, and so $ra\in I$ by the definition of $I$.
  Therefore $I$ is a right ideal of $R$.
  The same argument can be used to conclude that $I$ is also a left-ideal of $R$,
  since $J$ is a left-ideal of $\mathcal{M}_n(R)$. \\
  \indent For the second part of the exercise, suppose first that $A\in J$.
  Then, by exercise 3.5, we know that for any integers $i,j$ between $1$ and $n-1$,
  there is a matrix in $J$ with $A_{ij}$ at entry $(1,1)$.
  Thus, $A_{ij}\in I$. \\
  \indent Conversely, suppose $A$ is a matrix whose entries all belong to $I$.
  Then, for each entry $A_{ij}$ of $A$, the matrix $A_{ij}\cdot\eta(i,j)$ is in $J$ by
  the definition of $I$ and exercise 3.5, so their sum $A$ must also be in $J$ as $J$
  is closed under addition (due to it being an ideal).
  Therefore $J$ consists precisely of those matrices whose entries all belong to $I$.
\end{solution}

\begin{problem}{3.7}
  Let $R$ be a ring, and let $a\in R$.
  Prove that $Ra$ is a left-ideal of $R$ and $aR$ is a right-ideal of $R$.
  Prove that $a$ is a left-, resp. right-, unit if and only if $R=aR$, resp $R=Ra$.
\end{problem}
\begin{solution}
  First we will prove that $Ra$ is a left-ideal of $R$.
  Suppose $x\in Ra$ so that $x=ra$ for some $r\in R$.
  Then if $s\in R$, we have $sx=sra=(sr)a\in Ra$.
  Hence $Ra$ is a left ideal of $R$.
  A similar argument shows that $aR$ is a right-ideal of $R$. \\
  \indent For the second question, note that $R=aR$ (resp. $R=Ra$) if and only
  if left- resp. right- multiplication by $a$ is surjective, if and only if
  $a$ is a left- resp. right- ideal of $R$.
\end{solution}

\begin{problem}{3.8}
  Prove that a ring $R$ is a division ring if and only if the only
  left-ideals and right-ideals are $\{0\}$ and $R$.\\
  \indent In particular, a commutative ring $R$ is a field if and 
  only if the only ideals of $R$ are $\{0\}$ and $R$.
\end{problem}
\begin{solution}
  Suppose $R$ is a division ring, and $I$ is a right-ideal of $R$.
  Of course $\{0\}$ is a right-ideal of $R$, so suppose $r\neq0$ is an
  element of $I$.
  Then since $R$ is a division ring, $r$ has a two-sided inverse
  $r^{-1}$.
  Note, then, that since $I$ is an ideal of $R$, we have 
  $rr^{-1}=1_R\in I$, and so $I=R$. The same argument applies
  if $I$ is a left-ideal of $R$, completing the proof in one direction.\\
  \indent Conversely, suppose the only left- and right-ideals of $R$
  are $\{0\}$ and $R$ itself.
  Then it follows from exercise 3.7 that for all nonzero $a\in R$,
  we have $aR = R$ and $Ra = R$ (since $aR$ and $Ra$ are nonzero 
  ideals of $R$), and so $a$ is a left- and right-unit in $r$;
  hence every element of $R$ is a two-sided unit, and $R$ is
  a divison ring.
\end{solution}

\begin{problem}{3.9}
  Counterpoint to Exercise 3.8: It is \textit{not} true that a ring
  $R$ is a division ring if and only if its only two-sided ideals
  are $\{0\}$ and $R$.
  A nonzero ring with this property is said to be \textit{simple};
  by Exercise 3.8, fields are the only simple \textit{commutative}
  rings.\\
  \indent Prove that $\mathcal{M}_n(\mathbb{R})$ is simple. 
  (Use Exercise 3.6).
\end{problem}
\begin{solution}
  Suppose $J$ is a nonzero two-sided ideal of $\mathcal{M}_n(\mathbb{R})$.
  Let $\alpha$ be a nonzero entry of a matrix in $J$.
  Then, by exercise 3.5, the matrix with $\alpha$ at the position
  $(1,1)$ and $0$ elsewhere is in $J$.
  If we then multiply this matrix with the matrix that has $\alpha^{-1}$
  at position $(1,1)$, we then find (using the fact that $J$ is an ideal)
  that the matrix with $1$ at $(1,1)$ and zero elsewhere is in $J$.
  Applying 3.5 again and the fact that $J$ is closed under addition,
  we find that the identity matrix is in $J$, and so $J$ is the whole of 
  $\mathcal{M}_n(\mathbb{R})$.
  Therefore $\mathcal{M}_n(\mathbb{R})$ is simple.
\end{solution}

\newpage

\begin{problem}{3.10}
  Let $\varphi:k\to R$ be a ring homomorphism, where $k$ is a field
  and $R$ is a nonzero ring.
  Prove that $\varphi$ is injective.
\end{problem}
\begin{solution}
  Suppose $\nu\in k$ is nonzero and $\varphi(\nu) = 0$.
  Then we have
  \begin{align*}
    0 &= \varphi(\nu) \\
    &= \varphi(\nu)\varphi(\nu^{-1}) \\
    &= \varphi(\nu\nu^{-1}) \\
    &= \varphi(1) \\
    &= 1,
  \end{align*}
  which is a contradiction since $R$ is nonzero.
  Hence $\nu=0$ and $\varphi$ is injective.
\end{solution}

\begin{problem}{3.11}
  Let $R$ be a ring containing $\mathbb{C}$ as a subring.
  Prove that there are no ring homomorphisms $R\to\mathbb{R}$.
\end{problem}
\begin{solution}
  Since $\mathbb{C}$ is a subring of $R$, the element $i$ is then in $R$.
  Note, then, that $i^4=1$, and so if $\varphi$ is to be a 
  homomorphism $R\to\mathbb{R}$, we must then have $\varphi(i^4)=1$.
  Since this implies $\varphi(i)^4=1$, we then know that 
  $\varphi(i)$ is either $1$ or $-1$, since the only fourth roots
  of $1$ in $\mathbb{R}$ are $1$ and $-1$.
  Either way, we then have, since $\varphi$ is a homomorphism,
  that $\varphi(i^2) = \varphi(i)^2=1$.
  But we also have $\varphi(i^2)=\varphi(-1)=-\varphi(1)=-1$, which
  implies that $1=-1$.
  Since this is not true in $R$, we then know that $\varphi$ is not
  a homomorphism, and so there are no ring homomorphisms from $R$ 
  to $\mathbb{R}$.
\end{solution}

\end{document}
